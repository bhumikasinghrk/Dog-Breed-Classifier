{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.datasets import load_files\n",
    "from glob import glob\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout,Dense\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    data=load_files(path)\n",
    "    dog_files=np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset(r'C:\\Users\\Bhumika Singh\\Desktop\\Dog breed\\dogImages\\dogImages\\train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_files, valid_targets = load_dataset(r'C:\\Users\\Bhumika Singh\\Desktop\\Dog breed\\dogImages\\dogImages\\valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files, test_targets = load_dataset(r'C:\\Users\\Bhumika Singh\\Desktop\\Dog breed\\dogImages\\dogImages\\test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_files, valid_files, test_files - numpy arrays containing file paths to images\n",
    "\n",
    "#train_targets, valid_targets, test_targets - numpy arrays containing onehot-encoded classification labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 133 total dog categories.\n",
      "There are 8351 total dog images.\n",
      "\n",
      "There are 6680 training dog images.\n",
      "There are 835 validation dog images.\n",
      "There are 836 test dog images.\n"
     ]
    }
   ],
   "source": [
    "# load list of dog names\n",
    "dog_names = [item[20:-1] for item in sorted(glob(r'C:\\Users\\Bhumika Singh\\Desktop\\Dog breed\\dogImages\\dogImages\\train\\*'))]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total dog categories.' % len(dog_names))\n",
    "print('There are %s total dog images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training dog images.' % len(train_files))\n",
    "print('There are %d validation dog images.' % len(valid_files))\n",
    "print('There are %d test dog images.'% len(test_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50_model= ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 133)               272517    \n",
      "=================================================================\n",
      "Total params: 272,517\n",
      "Trainable params: 272,517\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "def ResNet50_predict_labels(img_path):\n",
    "    # returns prediction vector for image located at img_path\n",
    "    img = preprocess_input(path_to_tensor(img_path))\n",
    "    return np.argmax(ResNet50_model.predict(img))\n",
    "\n",
    "### returns \"True\" if a dog is detected in the image stored at img_path\n",
    "def dog_detector(img_path):\n",
    "    prediction = ResNet50_predict_labels(img_path)\n",
    "    return ((prediction <= 268) & (prediction >= 151))\n",
    "\n",
    "### Obtain bottleneck features from another pre-trained CNN.\n",
    "bottleneck_features = np.load(r'C:\\Users\\Bhumika Singh\\Desktop\\Dog breed\\dogImages\\DogResnet50Data.npz')\n",
    "train_DogResnet50 = bottleneck_features['train']\n",
    "valid_DogResnet50 = bottleneck_features['valid']\n",
    "test_DogResnet50 = bottleneck_features['test']\n",
    "\n",
    "### Define your architecture.\n",
    "Resnet50_model = Sequential()\n",
    "Resnet50_model.add(GlobalAveragePooling2D(input_shape=train_DogResnet50.shape[1:]))\n",
    "Resnet50_model.add(Dropout(0.3))\n",
    "Resnet50_model.add(Dense(units=133, activation='softmax'))\n",
    "\n",
    "Resnet50_model.summary()\n",
    "\n",
    "### Compile the model.\n",
    "#Resnet50_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "Resnet50_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "### Train the model.\n",
    "checkpointer = ModelCheckpoint(filepath=r'C:\\Users\\Bhumika Singh\\Desktop\\Dog breed\\saved_models\\weights.best.ResNet50.hdf5', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/20\n",
      "6680/6680 [==============================] - ETA: 2:32 - loss: 6.0139 - acc: 0.0000e+0 - ETA: 32s - loss: 5.9767 - acc: 0.0187    - ETA: 16s - loss: 5.8356 - acc: 0.02 - ETA: 11s - loss: 5.6237 - acc: 0.03 - ETA: 9s - loss: 5.3960 - acc: 0.0500 - ETA: 7s - loss: 5.1102 - acc: 0.070 - ETA: 6s - loss: 4.9013 - acc: 0.091 - ETA: 5s - loss: 4.6916 - acc: 0.110 - ETA: 5s - loss: 4.5026 - acc: 0.132 - ETA: 4s - loss: 4.3234 - acc: 0.150 - ETA: 4s - loss: 4.1548 - acc: 0.176 - ETA: 3s - loss: 3.9408 - acc: 0.207 - ETA: 3s - loss: 3.8344 - acc: 0.220 - ETA: 3s - loss: 3.7161 - acc: 0.236 - ETA: 2s - loss: 3.6069 - acc: 0.247 - ETA: 2s - loss: 3.5134 - acc: 0.260 - ETA: 2s - loss: 3.4125 - acc: 0.273 - ETA: 2s - loss: 3.3184 - acc: 0.289 - ETA: 2s - loss: 3.2280 - acc: 0.304 - ETA: 2s - loss: 3.1624 - acc: 0.313 - ETA: 2s - loss: 3.0929 - acc: 0.326 - ETA: 1s - loss: 3.0212 - acc: 0.338 - ETA: 1s - loss: 2.9477 - acc: 0.351 - ETA: 1s - loss: 2.9011 - acc: 0.359 - ETA: 1s - loss: 2.8479 - acc: 0.368 - ETA: 1s - loss: 2.7874 - acc: 0.377 - ETA: 1s - loss: 2.7376 - acc: 0.387 - ETA: 1s - loss: 2.6834 - acc: 0.396 - ETA: 1s - loss: 2.6474 - acc: 0.403 - ETA: 1s - loss: 2.6027 - acc: 0.412 - ETA: 1s - loss: 2.5673 - acc: 0.418 - ETA: 1s - loss: 2.5330 - acc: 0.424 - ETA: 0s - loss: 2.4874 - acc: 0.432 - ETA: 0s - loss: 2.4539 - acc: 0.438 - ETA: 0s - loss: 2.4277 - acc: 0.443 - ETA: 0s - loss: 2.3846 - acc: 0.451 - ETA: 0s - loss: 2.3481 - acc: 0.459 - ETA: 0s - loss: 2.3210 - acc: 0.464 - ETA: 0s - loss: 2.2875 - acc: 0.470 - ETA: 0s - loss: 2.2547 - acc: 0.477 - ETA: 0s - loss: 2.2283 - acc: 0.482 - ETA: 0s - loss: 2.2021 - acc: 0.488 - ETA: 0s - loss: 2.1824 - acc: 0.491 - ETA: 0s - loss: 2.1622 - acc: 0.495 - ETA: 0s - loss: 2.1380 - acc: 0.500 - 3s 519us/step - loss: 2.1229 - acc: 0.5034 - val_loss: 0.9085 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.90850, saving model to C:\\Users\\Bhumika Singh\\Desktop\\Dog breed\\saved_models\\weights.best.ResNet50.hdf5\n",
      "Epoch 2/20\n",
      "6680/6680 [==============================] - ETA: 3s - loss: 0.8102 - acc: 0.687 - ETA: 2s - loss: 0.5942 - acc: 0.838 - ETA: 2s - loss: 0.6460 - acc: 0.826 - ETA: 2s - loss: 0.6367 - acc: 0.834 - ETA: 2s - loss: 0.6241 - acc: 0.847 - ETA: 2s - loss: 0.6138 - acc: 0.847 - ETA: 2s - loss: 0.6144 - acc: 0.844 - ETA: 2s - loss: 0.6165 - acc: 0.843 - ETA: 2s - loss: 0.6126 - acc: 0.845 - ETA: 2s - loss: 0.6060 - acc: 0.845 - ETA: 1s - loss: 0.6099 - acc: 0.841 - ETA: 1s - loss: 0.6094 - acc: 0.839 - ETA: 1s - loss: 0.5963 - acc: 0.845 - ETA: 1s - loss: 0.5948 - acc: 0.845 - ETA: 1s - loss: 0.5953 - acc: 0.841 - ETA: 1s - loss: 0.5943 - acc: 0.842 - ETA: 1s - loss: 0.5921 - acc: 0.840 - ETA: 1s - loss: 0.5952 - acc: 0.839 - ETA: 1s - loss: 0.5919 - acc: 0.839 - ETA: 1s - loss: 0.5917 - acc: 0.838 - ETA: 1s - loss: 0.5933 - acc: 0.838 - ETA: 1s - loss: 0.5908 - acc: 0.838 - ETA: 1s - loss: 0.5912 - acc: 0.838 - ETA: 1s - loss: 0.5924 - acc: 0.836 - ETA: 1s - loss: 0.5931 - acc: 0.837 - ETA: 1s - loss: 0.5895 - acc: 0.837 - ETA: 1s - loss: 0.5890 - acc: 0.836 - ETA: 0s - loss: 0.5865 - acc: 0.836 - ETA: 0s - loss: 0.5895 - acc: 0.835 - ETA: 0s - loss: 0.5897 - acc: 0.833 - ETA: 0s - loss: 0.5925 - acc: 0.832 - ETA: 0s - loss: 0.5897 - acc: 0.832 - ETA: 0s - loss: 0.5929 - acc: 0.831 - ETA: 0s - loss: 0.5884 - acc: 0.832 - ETA: 0s - loss: 0.5841 - acc: 0.834 - ETA: 0s - loss: 0.5873 - acc: 0.832 - ETA: 0s - loss: 0.5896 - acc: 0.831 - ETA: 0s - loss: 0.5887 - acc: 0.831 - ETA: 0s - loss: 0.5900 - acc: 0.830 - ETA: 0s - loss: 0.5898 - acc: 0.829 - ETA: 0s - loss: 0.5882 - acc: 0.830 - ETA: 0s - loss: 0.5839 - acc: 0.831 - ETA: 0s - loss: 0.5810 - acc: 0.832 - ETA: 0s - loss: 0.5815 - acc: 0.832 - 3s 380us/step - loss: 0.5794 - acc: 0.8329 - val_loss: 0.7334 - val_acc: 0.7856\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.90850 to 0.73338, saving model to C:\\Users\\Bhumika Singh\\Desktop\\Dog breed\\saved_models\\weights.best.ResNet50.hdf5\n",
      "Epoch 3/20\n",
      "6680/6680 [==============================] - ETA: 2s - loss: 0.4487 - acc: 0.843 - ETA: 2s - loss: 0.3610 - acc: 0.893 - ETA: 2s - loss: 0.3570 - acc: 0.912 - ETA: 2s - loss: 0.3571 - acc: 0.906 - ETA: 2s - loss: 0.3633 - acc: 0.906 - ETA: 2s - loss: 0.3612 - acc: 0.902 - ETA: 2s - loss: 0.3654 - acc: 0.899 - ETA: 2s - loss: 0.3698 - acc: 0.900 - ETA: 2s - loss: 0.3602 - acc: 0.906 - ETA: 1s - loss: 0.3600 - acc: 0.905 - ETA: 1s - loss: 0.3605 - acc: 0.903 - ETA: 1s - loss: 0.3553 - acc: 0.904 - ETA: 1s - loss: 0.3508 - acc: 0.907 - ETA: 1s - loss: 0.3543 - acc: 0.903 - ETA: 1s - loss: 0.3555 - acc: 0.903 - ETA: 1s - loss: 0.3528 - acc: 0.904 - ETA: 1s - loss: 0.3526 - acc: 0.904 - ETA: 1s - loss: 0.3552 - acc: 0.902 - ETA: 1s - loss: 0.3504 - acc: 0.904 - ETA: 1s - loss: 0.3501 - acc: 0.904 - ETA: 1s - loss: 0.3471 - acc: 0.905 - ETA: 1s - loss: 0.3456 - acc: 0.906 - ETA: 1s - loss: 0.3443 - acc: 0.906 - ETA: 1s - loss: 0.3455 - acc: 0.905 - ETA: 1s - loss: 0.3460 - acc: 0.906 - ETA: 1s - loss: 0.3457 - acc: 0.905 - ETA: 1s - loss: 0.3427 - acc: 0.906 - ETA: 0s - loss: 0.3427 - acc: 0.906 - ETA: 0s - loss: 0.3404 - acc: 0.907 - ETA: 0s - loss: 0.3407 - acc: 0.906 - ETA: 0s - loss: 0.3425 - acc: 0.905 - ETA: 0s - loss: 0.3414 - acc: 0.906 - ETA: 0s - loss: 0.3439 - acc: 0.906 - ETA: 0s - loss: 0.3420 - acc: 0.907 - ETA: 0s - loss: 0.3420 - acc: 0.907 - ETA: 0s - loss: 0.3428 - acc: 0.906 - ETA: 0s - loss: 0.3426 - acc: 0.907 - ETA: 0s - loss: 0.3435 - acc: 0.907 - ETA: 0s - loss: 0.3426 - acc: 0.907 - ETA: 0s - loss: 0.3424 - acc: 0.907 - ETA: 0s - loss: 0.3422 - acc: 0.907 - ETA: 0s - loss: 0.3430 - acc: 0.906 - ETA: 0s - loss: 0.3436 - acc: 0.906 - ETA: 0s - loss: 0.3439 - acc: 0.906 - ETA: 0s - loss: 0.3417 - acc: 0.906 - ETA: 0s - loss: 0.3428 - acc: 0.905 - 3s 389us/step - loss: 0.3431 - acc: 0.9055 - val_loss: 0.6527 - val_acc: 0.8012\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.73338 to 0.65266, saving model to C:\\Users\\Bhumika Singh\\Desktop\\Dog breed\\saved_models\\weights.best.ResNet50.hdf5\n",
      "Epoch 4/20\n",
      "6680/6680 [==============================] - ETA: 4s - loss: 0.2316 - acc: 0.937 - ETA: 2s - loss: 0.2029 - acc: 0.968 - ETA: 2s - loss: 0.2023 - acc: 0.968 - ETA: 2s - loss: 0.1955 - acc: 0.963 - ETA: 2s - loss: 0.1948 - acc: 0.963 - ETA: 2s - loss: 0.2097 - acc: 0.954 - ETA: 2s - loss: 0.2156 - acc: 0.953 - ETA: 2s - loss: 0.2130 - acc: 0.956 - ETA: 2s - loss: 0.2105 - acc: 0.956 - ETA: 2s - loss: 0.2117 - acc: 0.954 - ETA: 2s - loss: 0.2167 - acc: 0.951 - ETA: 1s - loss: 0.2143 - acc: 0.953 - ETA: 1s - loss: 0.2136 - acc: 0.953 - ETA: 1s - loss: 0.2153 - acc: 0.952 - ETA: 1s - loss: 0.2177 - acc: 0.951 - ETA: 1s - loss: 0.2189 - acc: 0.951 - ETA: 1s - loss: 0.2174 - acc: 0.952 - ETA: 1s - loss: 0.2166 - acc: 0.952 - ETA: 1s - loss: 0.2140 - acc: 0.952 - ETA: 1s - loss: 0.2138 - acc: 0.952 - ETA: 1s - loss: 0.2130 - acc: 0.952 - ETA: 1s - loss: 0.2138 - acc: 0.951 - ETA: 1s - loss: 0.2116 - acc: 0.953 - ETA: 1s - loss: 0.2136 - acc: 0.952 - ETA: 1s - loss: 0.2175 - acc: 0.951 - ETA: 1s - loss: 0.2160 - acc: 0.952 - ETA: 1s - loss: 0.2157 - acc: 0.952 - ETA: 1s - loss: 0.2163 - acc: 0.951 - ETA: 1s - loss: 0.2161 - acc: 0.952 - ETA: 1s - loss: 0.2164 - acc: 0.952 - ETA: 1s - loss: 0.2173 - acc: 0.951 - ETA: 1s - loss: 0.2187 - acc: 0.950 - ETA: 1s - loss: 0.2181 - acc: 0.950 - ETA: 1s - loss: 0.2169 - acc: 0.950 - ETA: 0s - loss: 0.2140 - acc: 0.952 - ETA: 0s - loss: 0.2135 - acc: 0.951 - ETA: 0s - loss: 0.2122 - acc: 0.951 - ETA: 0s - loss: 0.2124 - acc: 0.951 - ETA: 0s - loss: 0.2122 - acc: 0.951 - ETA: 0s - loss: 0.2131 - acc: 0.951 - ETA: 0s - loss: 0.2125 - acc: 0.950 - ETA: 0s - loss: 0.2139 - acc: 0.950 - ETA: 0s - loss: 0.2144 - acc: 0.949 - ETA: 0s - loss: 0.2156 - acc: 0.949 - ETA: 0s - loss: 0.2144 - acc: 0.949 - ETA: 0s - loss: 0.2146 - acc: 0.950 - ETA: 0s - loss: 0.2146 - acc: 0.949 - ETA: 0s - loss: 0.2172 - acc: 0.948 - ETA: 0s - loss: 0.2177 - acc: 0.948 - ETA: 0s - loss: 0.2187 - acc: 0.948 - ETA: 0s - loss: 0.2190 - acc: 0.947 - 3s 433us/step - loss: 0.2185 - acc: 0.9473 - val_loss: 0.6505 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.65266 to 0.65049, saving model to C:\\Users\\Bhumika Singh\\Desktop\\Dog breed\\saved_models\\weights.best.ResNet50.hdf5\n",
      "Epoch 5/20\n",
      "6680/6680 [==============================] - ETA: 3s - loss: 0.0972 - acc: 1.000 - ETA: 2s - loss: 0.1353 - acc: 0.975 - ETA: 2s - loss: 0.1327 - acc: 0.972 - ETA: 2s - loss: 0.1488 - acc: 0.966 - ETA: 2s - loss: 0.1409 - acc: 0.970 - ETA: 2s - loss: 0.1446 - acc: 0.970 - ETA: 2s - loss: 0.1484 - acc: 0.967 - ETA: 2s - loss: 0.1515 - acc: 0.968 - ETA: 2s - loss: 0.1505 - acc: 0.968 - ETA: 2s - loss: 0.1504 - acc: 0.969 - ETA: 2s - loss: 0.1538 - acc: 0.967 - ETA: 1s - loss: 0.1494 - acc: 0.969 - ETA: 1s - loss: 0.1502 - acc: 0.969 - ETA: 1s - loss: 0.1509 - acc: 0.969 - ETA: 1s - loss: 0.1477 - acc: 0.971 - ETA: 1s - loss: 0.1465 - acc: 0.972 - ETA: 1s - loss: 0.1468 - acc: 0.971 - ETA: 1s - loss: 0.1491 - acc: 0.970 - ETA: 1s - loss: 0.1487 - acc: 0.970 - ETA: 1s - loss: 0.1508 - acc: 0.969 - ETA: 1s - loss: 0.1519 - acc: 0.970 - ETA: 1s - loss: 0.1519 - acc: 0.970 - ETA: 1s - loss: 0.1513 - acc: 0.970 - ETA: 1s - loss: 0.1502 - acc: 0.971 - ETA: 1s - loss: 0.1514 - acc: 0.971 - ETA: 1s - loss: 0.1515 - acc: 0.971 - ETA: 1s - loss: 0.1512 - acc: 0.971 - ETA: 1s - loss: 0.1535 - acc: 0.970 - ETA: 1s - loss: 0.1549 - acc: 0.969 - ETA: 1s - loss: 0.1548 - acc: 0.969 - ETA: 0s - loss: 0.1560 - acc: 0.969 - ETA: 0s - loss: 0.1580 - acc: 0.968 - ETA: 0s - loss: 0.1593 - acc: 0.968 - ETA: 0s - loss: 0.1600 - acc: 0.967 - ETA: 0s - loss: 0.1602 - acc: 0.966 - ETA: 0s - loss: 0.1600 - acc: 0.966 - ETA: 0s - loss: 0.1601 - acc: 0.966 - ETA: 0s - loss: 0.1586 - acc: 0.966 - ETA: 0s - loss: 0.1596 - acc: 0.965 - ETA: 0s - loss: 0.1600 - acc: 0.965 - ETA: 0s - loss: 0.1602 - acc: 0.965 - ETA: 0s - loss: 0.1606 - acc: 0.965 - ETA: 0s - loss: 0.1604 - acc: 0.964 - ETA: 0s - loss: 0.1613 - acc: 0.964 - ETA: 0s - loss: 0.1619 - acc: 0.964 - ETA: 0s - loss: 0.1620 - acc: 0.964 - ETA: 0s - loss: 0.1617 - acc: 0.964 - ETA: 0s - loss: 0.1622 - acc: 0.964 - ETA: 0s - loss: 0.1617 - acc: 0.964 - 3s 409us/step - loss: 0.1620 - acc: 0.9644 - val_loss: 0.6067 - val_acc: 0.8108\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.65049 to 0.60671, saving model to C:\\Users\\Bhumika Singh\\Desktop\\Dog breed\\saved_models\\weights.best.ResNet50.hdf5\n",
      "Epoch 6/20\n",
      "6680/6680 [==============================] - ETA: 2s - loss: 0.1519 - acc: 0.968 - ETA: 2s - loss: 0.0916 - acc: 0.993 - ETA: 2s - loss: 0.0971 - acc: 0.989 - ETA: 2s - loss: 0.1184 - acc: 0.976 - ETA: 2s - loss: 0.1125 - acc: 0.977 - ETA: 2s - loss: 0.1244 - acc: 0.970 - ETA: 2s - loss: 0.1268 - acc: 0.970 - ETA: 2s - loss: 0.1220 - acc: 0.973 - ETA: 2s - loss: 0.1230 - acc: 0.972 - ETA: 2s - loss: 0.1235 - acc: 0.972 - ETA: 2s - loss: 0.1222 - acc: 0.972 - ETA: 2s - loss: 0.1195 - acc: 0.975 - ETA: 2s - loss: 0.1180 - acc: 0.976 - ETA: 1s - loss: 0.1167 - acc: 0.976 - ETA: 1s - loss: 0.1164 - acc: 0.975 - ETA: 1s - loss: 0.1138 - acc: 0.976 - ETA: 1s - loss: 0.1124 - acc: 0.977 - ETA: 1s - loss: 0.1133 - acc: 0.976 - ETA: 1s - loss: 0.1155 - acc: 0.976 - ETA: 1s - loss: 0.1152 - acc: 0.976 - ETA: 1s - loss: 0.1147 - acc: 0.977 - ETA: 1s - loss: 0.1155 - acc: 0.977 - ETA: 1s - loss: 0.1167 - acc: 0.976 - ETA: 1s - loss: 0.1162 - acc: 0.976 - ETA: 1s - loss: 0.1164 - acc: 0.976 - ETA: 1s - loss: 0.1161 - acc: 0.976 - ETA: 1s - loss: 0.1154 - acc: 0.977 - ETA: 1s - loss: 0.1189 - acc: 0.976 - ETA: 1s - loss: 0.1186 - acc: 0.976 - ETA: 1s - loss: 0.1190 - acc: 0.976 - ETA: 1s - loss: 0.1184 - acc: 0.975 - ETA: 1s - loss: 0.1185 - acc: 0.976 - ETA: 0s - loss: 0.1177 - acc: 0.976 - ETA: 0s - loss: 0.1191 - acc: 0.976 - ETA: 0s - loss: 0.1186 - acc: 0.976 - ETA: 0s - loss: 0.1184 - acc: 0.976 - ETA: 0s - loss: 0.1188 - acc: 0.976 - ETA: 0s - loss: 0.1187 - acc: 0.976 - ETA: 0s - loss: 0.1196 - acc: 0.975 - ETA: 0s - loss: 0.1199 - acc: 0.975 - ETA: 0s - loss: 0.1194 - acc: 0.975 - ETA: 0s - loss: 0.1206 - acc: 0.975 - ETA: 0s - loss: 0.1204 - acc: 0.975 - ETA: 0s - loss: 0.1208 - acc: 0.975 - ETA: 0s - loss: 0.1198 - acc: 0.975 - ETA: 0s - loss: 0.1196 - acc: 0.975 - ETA: 0s - loss: 0.1191 - acc: 0.975 - ETA: 0s - loss: 0.1191 - acc: 0.975 - ETA: 0s - loss: 0.1194 - acc: 0.975 - ETA: 0s - loss: 0.1202 - acc: 0.975 - 3s 416us/step - loss: 0.1199 - acc: 0.9756 - val_loss: 0.6009 - val_acc: 0.8168\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.60671 to 0.60092, saving model to C:\\Users\\Bhumika Singh\\Desktop\\Dog breed\\saved_models\\weights.best.ResNet50.hdf5\n",
      "Epoch 7/20\n",
      "6680/6680 [==============================] - ETA: 5s - loss: 0.0666 - acc: 0.968 - ETA: 3s - loss: 0.0528 - acc: 0.993 - ETA: 3s - loss: 0.0673 - acc: 0.993 - ETA: 2s - loss: 0.0707 - acc: 0.990 - ETA: 2s - loss: 0.0796 - acc: 0.989 - ETA: 2s - loss: 0.0894 - acc: 0.985 - ETA: 2s - loss: 0.0872 - acc: 0.986 - ETA: 2s - loss: 0.0835 - acc: 0.988 - ETA: 2s - loss: 0.0852 - acc: 0.987 - ETA: 2s - loss: 0.0838 - acc: 0.988 - ETA: 2s - loss: 0.0836 - acc: 0.988 - ETA: 2s - loss: 0.0845 - acc: 0.988 - ETA: 2s - loss: 0.0853 - acc: 0.987 - ETA: 2s - loss: 0.0868 - acc: 0.986 - ETA: 2s - loss: 0.0854 - acc: 0.986 - ETA: 1s - loss: 0.0855 - acc: 0.987 - ETA: 1s - loss: 0.0849 - acc: 0.987 - ETA: 1s - loss: 0.0847 - acc: 0.988 - ETA: 1s - loss: 0.0862 - acc: 0.987 - ETA: 1s - loss: 0.0855 - acc: 0.988 - ETA: 1s - loss: 0.0875 - acc: 0.987 - ETA: 1s - loss: 0.0875 - acc: 0.987 - ETA: 1s - loss: 0.0877 - acc: 0.987 - ETA: 1s - loss: 0.0875 - acc: 0.986 - ETA: 1s - loss: 0.0879 - acc: 0.986 - ETA: 1s - loss: 0.0889 - acc: 0.986 - ETA: 1s - loss: 0.0903 - acc: 0.986 - ETA: 1s - loss: 0.0907 - acc: 0.985 - ETA: 1s - loss: 0.0920 - acc: 0.984 - ETA: 1s - loss: 0.0913 - acc: 0.985 - ETA: 1s - loss: 0.0912 - acc: 0.985 - ETA: 1s - loss: 0.0904 - acc: 0.985 - ETA: 1s - loss: 0.0910 - acc: 0.985 - ETA: 0s - loss: 0.0907 - acc: 0.985 - ETA: 0s - loss: 0.0908 - acc: 0.985 - ETA: 0s - loss: 0.0918 - acc: 0.985 - ETA: 0s - loss: 0.0933 - acc: 0.984 - ETA: 0s - loss: 0.0931 - acc: 0.984 - ETA: 0s - loss: 0.0927 - acc: 0.984 - ETA: 0s - loss: 0.0931 - acc: 0.984 - ETA: 0s - loss: 0.0940 - acc: 0.983 - ETA: 0s - loss: 0.0940 - acc: 0.983 - ETA: 0s - loss: 0.0935 - acc: 0.983 - ETA: 0s - loss: 0.0936 - acc: 0.983 - ETA: 0s - loss: 0.0933 - acc: 0.983 - ETA: 0s - loss: 0.0933 - acc: 0.983 - ETA: 0s - loss: 0.0933 - acc: 0.983 - ETA: 0s - loss: 0.0934 - acc: 0.983 - ETA: 0s - loss: 0.0932 - acc: 0.983 - ETA: 0s - loss: 0.0926 - acc: 0.984 - ETA: 0s - loss: 0.0925 - acc: 0.984 - 3s 424us/step - loss: 0.0926 - acc: 0.9844 - val_loss: 0.6018 - val_acc: 0.8204\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.60092\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - ETA: 3s - loss: 0.0647 - acc: 1.000 - ETA: 2s - loss: 0.0733 - acc: 0.979 - ETA: 2s - loss: 0.0864 - acc: 0.985 - ETA: 2s - loss: 0.0797 - acc: 0.986 - ETA: 2s - loss: 0.0759 - acc: 0.988 - ETA: 2s - loss: 0.0733 - acc: 0.988 - ETA: 2s - loss: 0.0739 - acc: 0.986 - ETA: 2s - loss: 0.0750 - acc: 0.986 - ETA: 2s - loss: 0.0759 - acc: 0.985 - ETA: 1s - loss: 0.0748 - acc: 0.987 - ETA: 1s - loss: 0.0761 - acc: 0.985 - ETA: 1s - loss: 0.0765 - acc: 0.985 - ETA: 1s - loss: 0.0754 - acc: 0.986 - ETA: 1s - loss: 0.0761 - acc: 0.986 - ETA: 1s - loss: 0.0748 - acc: 0.986 - ETA: 1s - loss: 0.0772 - acc: 0.985 - ETA: 1s - loss: 0.0766 - acc: 0.986 - ETA: 1s - loss: 0.0760 - acc: 0.986 - ETA: 1s - loss: 0.0758 - acc: 0.986 - ETA: 1s - loss: 0.0769 - acc: 0.986 - ETA: 1s - loss: 0.0767 - acc: 0.986 - ETA: 1s - loss: 0.0763 - acc: 0.986 - ETA: 1s - loss: 0.0770 - acc: 0.986 - ETA: 1s - loss: 0.0770 - acc: 0.986 - ETA: 1s - loss: 0.0767 - acc: 0.986 - ETA: 1s - loss: 0.0770 - acc: 0.987 - ETA: 1s - loss: 0.0765 - acc: 0.987 - ETA: 1s - loss: 0.0764 - acc: 0.987 - ETA: 1s - loss: 0.0768 - acc: 0.987 - ETA: 0s - loss: 0.0774 - acc: 0.987 - ETA: 0s - loss: 0.0765 - acc: 0.987 - ETA: 0s - loss: 0.0764 - acc: 0.987 - ETA: 0s - loss: 0.0762 - acc: 0.987 - ETA: 0s - loss: 0.0759 - acc: 0.987 - ETA: 0s - loss: 0.0756 - acc: 0.988 - ETA: 0s - loss: 0.0761 - acc: 0.987 - ETA: 0s - loss: 0.0763 - acc: 0.987 - ETA: 0s - loss: 0.0756 - acc: 0.988 - ETA: 0s - loss: 0.0755 - acc: 0.988 - ETA: 0s - loss: 0.0763 - acc: 0.987 - ETA: 0s - loss: 0.0770 - acc: 0.987 - ETA: 0s - loss: 0.0764 - acc: 0.987 - ETA: 0s - loss: 0.0758 - acc: 0.987 - ETA: 0s - loss: 0.0761 - acc: 0.987 - ETA: 0s - loss: 0.0767 - acc: 0.986 - ETA: 0s - loss: 0.0763 - acc: 0.987 - ETA: 0s - loss: 0.0762 - acc: 0.987 - 3s 399us/step - loss: 0.0764 - acc: 0.9870 - val_loss: 0.6058 - val_acc: 0.8228\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.60092\n",
      "Epoch 9/20\n",
      "6680/6680 [==============================] - ETA: 3s - loss: 0.0374 - acc: 1.000 - ETA: 2s - loss: 0.0575 - acc: 0.993 - ETA: 2s - loss: 0.0597 - acc: 0.990 - ETA: 2s - loss: 0.0678 - acc: 0.985 - ETA: 2s - loss: 0.0711 - acc: 0.982 - ETA: 2s - loss: 0.0700 - acc: 0.986 - ETA: 2s - loss: 0.0670 - acc: 0.988 - ETA: 2s - loss: 0.0657 - acc: 0.989 - ETA: 2s - loss: 0.0647 - acc: 0.990 - ETA: 2s - loss: 0.0628 - acc: 0.991 - ETA: 1s - loss: 0.0616 - acc: 0.992 - ETA: 1s - loss: 0.0655 - acc: 0.990 - ETA: 1s - loss: 0.0642 - acc: 0.990 - ETA: 1s - loss: 0.0627 - acc: 0.991 - ETA: 1s - loss: 0.0639 - acc: 0.990 - ETA: 1s - loss: 0.0678 - acc: 0.990 - ETA: 1s - loss: 0.0672 - acc: 0.990 - ETA: 1s - loss: 0.0674 - acc: 0.991 - ETA: 1s - loss: 0.0665 - acc: 0.991 - ETA: 1s - loss: 0.0653 - acc: 0.991 - ETA: 1s - loss: 0.0647 - acc: 0.991 - ETA: 1s - loss: 0.0656 - acc: 0.991 - ETA: 1s - loss: 0.0657 - acc: 0.991 - ETA: 1s - loss: 0.0651 - acc: 0.991 - ETA: 1s - loss: 0.0643 - acc: 0.991 - ETA: 1s - loss: 0.0645 - acc: 0.991 - ETA: 0s - loss: 0.0652 - acc: 0.990 - ETA: 0s - loss: 0.0658 - acc: 0.990 - ETA: 0s - loss: 0.0655 - acc: 0.990 - ETA: 0s - loss: 0.0660 - acc: 0.990 - ETA: 0s - loss: 0.0670 - acc: 0.990 - ETA: 0s - loss: 0.0668 - acc: 0.990 - ETA: 0s - loss: 0.0665 - acc: 0.990 - ETA: 0s - loss: 0.0666 - acc: 0.990 - ETA: 0s - loss: 0.0668 - acc: 0.990 - ETA: 0s - loss: 0.0665 - acc: 0.990 - ETA: 0s - loss: 0.0664 - acc: 0.990 - ETA: 0s - loss: 0.0668 - acc: 0.990 - ETA: 0s - loss: 0.0662 - acc: 0.990 - ETA: 0s - loss: 0.0660 - acc: 0.990 - ETA: 0s - loss: 0.0662 - acc: 0.990 - ETA: 0s - loss: 0.0660 - acc: 0.989 - ETA: 0s - loss: 0.0663 - acc: 0.990 - 2s 367us/step - loss: 0.0662 - acc: 0.9898 - val_loss: 0.6135 - val_acc: 0.8132\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.60092\n",
      "Epoch 10/20\n",
      "6680/6680 [==============================] - ETA: 3s - loss: 0.0865 - acc: 0.968 - ETA: 2s - loss: 0.0597 - acc: 0.993 - ETA: 2s - loss: 0.0526 - acc: 0.996 - ETA: 2s - loss: 0.0564 - acc: 0.993 - ETA: 2s - loss: 0.0557 - acc: 0.993 - ETA: 2s - loss: 0.0580 - acc: 0.992 - ETA: 2s - loss: 0.0572 - acc: 0.991 - ETA: 2s - loss: 0.0566 - acc: 0.992 - ETA: 2s - loss: 0.0544 - acc: 0.993 - ETA: 2s - loss: 0.0535 - acc: 0.993 - ETA: 2s - loss: 0.0542 - acc: 0.992 - ETA: 2s - loss: 0.0537 - acc: 0.992 - ETA: 1s - loss: 0.0544 - acc: 0.992 - ETA: 1s - loss: 0.0530 - acc: 0.992 - ETA: 1s - loss: 0.0519 - acc: 0.992 - ETA: 1s - loss: 0.0533 - acc: 0.992 - ETA: 1s - loss: 0.0531 - acc: 0.993 - ETA: 1s - loss: 0.0531 - acc: 0.993 - ETA: 1s - loss: 0.0528 - acc: 0.993 - ETA: 1s - loss: 0.0524 - acc: 0.993 - ETA: 1s - loss: 0.0528 - acc: 0.993 - ETA: 1s - loss: 0.0537 - acc: 0.992 - ETA: 1s - loss: 0.0541 - acc: 0.992 - ETA: 1s - loss: 0.0541 - acc: 0.992 - ETA: 1s - loss: 0.0547 - acc: 0.991 - ETA: 1s - loss: 0.0544 - acc: 0.992 - ETA: 1s - loss: 0.0547 - acc: 0.992 - ETA: 1s - loss: 0.0555 - acc: 0.991 - ETA: 1s - loss: 0.0558 - acc: 0.990 - ETA: 1s - loss: 0.0554 - acc: 0.991 - ETA: 0s - loss: 0.0559 - acc: 0.990 - ETA: 0s - loss: 0.0566 - acc: 0.990 - ETA: 0s - loss: 0.0565 - acc: 0.990 - ETA: 0s - loss: 0.0567 - acc: 0.990 - ETA: 0s - loss: 0.0561 - acc: 0.990 - ETA: 0s - loss: 0.0560 - acc: 0.990 - ETA: 0s - loss: 0.0558 - acc: 0.990 - ETA: 0s - loss: 0.0557 - acc: 0.990 - ETA: 0s - loss: 0.0561 - acc: 0.990 - ETA: 0s - loss: 0.0559 - acc: 0.990 - ETA: 0s - loss: 0.0557 - acc: 0.990 - ETA: 0s - loss: 0.0565 - acc: 0.989 - ETA: 0s - loss: 0.0559 - acc: 0.990 - ETA: 0s - loss: 0.0560 - acc: 0.990 - ETA: 0s - loss: 0.0558 - acc: 0.990 - ETA: 0s - loss: 0.0558 - acc: 0.990 - ETA: 0s - loss: 0.0560 - acc: 0.989 - ETA: 0s - loss: 0.0564 - acc: 0.989 - 3s 404us/step - loss: 0.0562 - acc: 0.9897 - val_loss: 0.6128 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.60092\n",
      "Epoch 11/20\n",
      "6680/6680 [==============================] - ETA: 3s - loss: 0.0455 - acc: 1.000 - ETA: 2s - loss: 0.0290 - acc: 1.000 - ETA: 2s - loss: 0.0336 - acc: 1.000 - ETA: 2s - loss: 0.0338 - acc: 0.997 - ETA: 2s - loss: 0.0433 - acc: 0.995 - ETA: 2s - loss: 0.0417 - acc: 0.996 - ETA: 2s - loss: 0.0405 - acc: 0.996 - ETA: 2s - loss: 0.0416 - acc: 0.996 - ETA: 2s - loss: 0.0417 - acc: 0.995 - ETA: 2s - loss: 0.0404 - acc: 0.995 - ETA: 1s - loss: 0.0414 - acc: 0.994 - ETA: 1s - loss: 0.0419 - acc: 0.994 - ETA: 1s - loss: 0.0427 - acc: 0.994 - ETA: 1s - loss: 0.0425 - acc: 0.994 - ETA: 1s - loss: 0.0416 - acc: 0.994 - ETA: 1s - loss: 0.0419 - acc: 0.994 - ETA: 1s - loss: 0.0411 - acc: 0.994 - ETA: 1s - loss: 0.0413 - acc: 0.994 - ETA: 1s - loss: 0.0407 - acc: 0.994 - ETA: 1s - loss: 0.0410 - acc: 0.994 - ETA: 1s - loss: 0.0411 - acc: 0.995 - ETA: 1s - loss: 0.0411 - acc: 0.994 - ETA: 1s - loss: 0.0421 - acc: 0.994 - ETA: 1s - loss: 0.0419 - acc: 0.994 - ETA: 1s - loss: 0.0417 - acc: 0.994 - ETA: 1s - loss: 0.0419 - acc: 0.995 - ETA: 1s - loss: 0.0422 - acc: 0.994 - ETA: 1s - loss: 0.0424 - acc: 0.994 - ETA: 0s - loss: 0.0439 - acc: 0.994 - ETA: 0s - loss: 0.0439 - acc: 0.994 - ETA: 0s - loss: 0.0438 - acc: 0.994 - ETA: 0s - loss: 0.0434 - acc: 0.994 - ETA: 0s - loss: 0.0435 - acc: 0.994 - ETA: 0s - loss: 0.0436 - acc: 0.994 - ETA: 0s - loss: 0.0436 - acc: 0.994 - ETA: 0s - loss: 0.0434 - acc: 0.995 - ETA: 0s - loss: 0.0434 - acc: 0.994 - ETA: 0s - loss: 0.0436 - acc: 0.994 - ETA: 0s - loss: 0.0434 - acc: 0.994 - ETA: 0s - loss: 0.0435 - acc: 0.994 - ETA: 0s - loss: 0.0432 - acc: 0.994 - ETA: 0s - loss: 0.0433 - acc: 0.995 - ETA: 0s - loss: 0.0435 - acc: 0.994 - ETA: 0s - loss: 0.0437 - acc: 0.994 - ETA: 0s - loss: 0.0442 - acc: 0.994 - ETA: 0s - loss: 0.0439 - acc: 0.994 - ETA: 0s - loss: 0.0439 - acc: 0.994 - 3s 410us/step - loss: 0.0441 - acc: 0.9948 - val_loss: 0.5794 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.60092 to 0.57936, saving model to C:\\Users\\Bhumika Singh\\Desktop\\Dog breed\\saved_models\\weights.best.ResNet50.hdf5\n",
      "Epoch 12/20\n",
      "6680/6680 [==============================] - ETA: 3s - loss: 0.0377 - acc: 1.000 - ETA: 2s - loss: 0.0325 - acc: 1.000 - ETA: 2s - loss: 0.0285 - acc: 1.000 - ETA: 2s - loss: 0.0277 - acc: 1.000 - ETA: 2s - loss: 0.0304 - acc: 1.000 - ETA: 2s - loss: 0.0284 - acc: 1.000 - ETA: 2s - loss: 0.0305 - acc: 0.998 - ETA: 2s - loss: 0.0312 - acc: 0.999 - ETA: 2s - loss: 0.0311 - acc: 0.999 - ETA: 2s - loss: 0.0310 - acc: 0.999 - ETA: 1s - loss: 0.0303 - acc: 0.999 - ETA: 1s - loss: 0.0320 - acc: 0.998 - ETA: 1s - loss: 0.0321 - acc: 0.998 - ETA: 1s - loss: 0.0331 - acc: 0.998 - ETA: 1s - loss: 0.0330 - acc: 0.998 - ETA: 1s - loss: 0.0324 - acc: 0.998 - ETA: 1s - loss: 0.0339 - acc: 0.997 - ETA: 1s - loss: 0.0353 - acc: 0.997 - ETA: 1s - loss: 0.0346 - acc: 0.997 - ETA: 1s - loss: 0.0348 - acc: 0.997 - ETA: 1s - loss: 0.0365 - acc: 0.996 - ETA: 1s - loss: 0.0368 - acc: 0.996 - ETA: 1s - loss: 0.0367 - acc: 0.996 - ETA: 1s - loss: 0.0362 - acc: 0.996 - ETA: 1s - loss: 0.0359 - acc: 0.996 - ETA: 1s - loss: 0.0360 - acc: 0.996 - ETA: 0s - loss: 0.0360 - acc: 0.996 - ETA: 0s - loss: 0.0360 - acc: 0.996 - ETA: 0s - loss: 0.0361 - acc: 0.996 - ETA: 0s - loss: 0.0361 - acc: 0.996 - ETA: 0s - loss: 0.0360 - acc: 0.996 - ETA: 0s - loss: 0.0362 - acc: 0.996 - ETA: 0s - loss: 0.0359 - acc: 0.996 - ETA: 0s - loss: 0.0358 - acc: 0.997 - ETA: 0s - loss: 0.0358 - acc: 0.997 - ETA: 0s - loss: 0.0359 - acc: 0.997 - ETA: 0s - loss: 0.0355 - acc: 0.997 - ETA: 0s - loss: 0.0360 - acc: 0.996 - ETA: 0s - loss: 0.0364 - acc: 0.996 - ETA: 0s - loss: 0.0365 - acc: 0.996 - ETA: 0s - loss: 0.0363 - acc: 0.996 - ETA: 0s - loss: 0.0370 - acc: 0.996 - ETA: 0s - loss: 0.0370 - acc: 0.996 - ETA: 0s - loss: 0.0369 - acc: 0.996 - ETA: 0s - loss: 0.0368 - acc: 0.996 - 3s 388us/step - loss: 0.0369 - acc: 0.9963 - val_loss: 0.6210 - val_acc: 0.8228\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.57936\n",
      "Epoch 13/20\n",
      "6680/6680 [==============================] - ETA: 7s - loss: 0.0336 - acc: 1.000 - ETA: 3s - loss: 0.0227 - acc: 1.000 - ETA: 2s - loss: 0.0285 - acc: 0.996 - ETA: 2s - loss: 0.0314 - acc: 0.997 - ETA: 2s - loss: 0.0301 - acc: 0.998 - ETA: 2s - loss: 0.0292 - acc: 0.998 - ETA: 3s - loss: 0.0307 - acc: 0.997 - ETA: 3s - loss: 0.0293 - acc: 0.997 - ETA: 3s - loss: 0.0298 - acc: 0.997 - ETA: 2s - loss: 0.0286 - acc: 0.997 - ETA: 2s - loss: 0.0290 - acc: 0.997 - ETA: 2s - loss: 0.0286 - acc: 0.997 - ETA: 2s - loss: 0.0312 - acc: 0.996 - ETA: 2s - loss: 0.0325 - acc: 0.995 - ETA: 2s - loss: 0.0338 - acc: 0.995 - ETA: 2s - loss: 0.0325 - acc: 0.995 - ETA: 2s - loss: 0.0335 - acc: 0.995 - ETA: 2s - loss: 0.0333 - acc: 0.995 - ETA: 2s - loss: 0.0334 - acc: 0.996 - ETA: 2s - loss: 0.0335 - acc: 0.996 - ETA: 1s - loss: 0.0332 - acc: 0.996 - ETA: 1s - loss: 0.0343 - acc: 0.995 - ETA: 1s - loss: 0.0343 - acc: 0.996 - ETA: 1s - loss: 0.0346 - acc: 0.995 - ETA: 1s - loss: 0.0347 - acc: 0.995 - ETA: 1s - loss: 0.0366 - acc: 0.994 - ETA: 1s - loss: 0.0370 - acc: 0.994 - ETA: 1s - loss: 0.0364 - acc: 0.995 - ETA: 1s - loss: 0.0360 - acc: 0.994 - ETA: 1s - loss: 0.0361 - acc: 0.994 - ETA: 1s - loss: 0.0363 - acc: 0.995 - ETA: 1s - loss: 0.0361 - acc: 0.994 - ETA: 1s - loss: 0.0370 - acc: 0.994 - ETA: 1s - loss: 0.0368 - acc: 0.994 - ETA: 1s - loss: 0.0366 - acc: 0.994 - ETA: 0s - loss: 0.0368 - acc: 0.994 - ETA: 0s - loss: 0.0378 - acc: 0.994 - ETA: 0s - loss: 0.0374 - acc: 0.994 - ETA: 0s - loss: 0.0374 - acc: 0.994 - ETA: 0s - loss: 0.0374 - acc: 0.994 - ETA: 0s - loss: 0.0374 - acc: 0.994 - ETA: 0s - loss: 0.0372 - acc: 0.995 - ETA: 0s - loss: 0.0370 - acc: 0.995 - ETA: 0s - loss: 0.0367 - acc: 0.995 - ETA: 0s - loss: 0.0367 - acc: 0.995 - ETA: 0s - loss: 0.0367 - acc: 0.995 - ETA: 0s - loss: 0.0366 - acc: 0.995 - ETA: 0s - loss: 0.0365 - acc: 0.995 - ETA: 0s - loss: 0.0364 - acc: 0.995 - ETA: 0s - loss: 0.0364 - acc: 0.995 - ETA: 0s - loss: 0.0364 - acc: 0.995 - ETA: 0s - loss: 0.0361 - acc: 0.995 - ETA: 0s - loss: 0.0363 - acc: 0.995 - ETA: 0s - loss: 0.0362 - acc: 0.995 - 3s 477us/step - loss: 0.0364 - acc: 0.9955 - val_loss: 0.6037 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.57936\n",
      "Epoch 14/20\n",
      "6680/6680 [==============================] - ETA: 5s - loss: 0.0280 - acc: 1.000 - ETA: 3s - loss: 0.0342 - acc: 0.993 - ETA: 2s - loss: 0.0339 - acc: 0.993 - ETA: 2s - loss: 0.0342 - acc: 0.995 - ETA: 2s - loss: 0.0430 - acc: 0.992 - ETA: 2s - loss: 0.0388 - acc: 0.994 - ETA: 2s - loss: 0.0382 - acc: 0.993 - ETA: 2s - loss: 0.0391 - acc: 0.993 - ETA: 2s - loss: 0.0398 - acc: 0.993 - ETA: 2s - loss: 0.0397 - acc: 0.993 - ETA: 2s - loss: 0.0388 - acc: 0.993 - ETA: 2s - loss: 0.0378 - acc: 0.994 - ETA: 2s - loss: 0.0373 - acc: 0.994 - ETA: 2s - loss: 0.0378 - acc: 0.994 - ETA: 2s - loss: 0.0378 - acc: 0.994 - ETA: 1s - loss: 0.0377 - acc: 0.994 - ETA: 1s - loss: 0.0370 - acc: 0.994 - ETA: 1s - loss: 0.0363 - acc: 0.994 - ETA: 1s - loss: 0.0352 - acc: 0.994 - ETA: 1s - loss: 0.0348 - acc: 0.994 - ETA: 1s - loss: 0.0350 - acc: 0.994 - ETA: 1s - loss: 0.0353 - acc: 0.994 - ETA: 1s - loss: 0.0354 - acc: 0.994 - ETA: 1s - loss: 0.0345 - acc: 0.994 - ETA: 1s - loss: 0.0339 - acc: 0.994 - ETA: 1s - loss: 0.0336 - acc: 0.995 - ETA: 1s - loss: 0.0343 - acc: 0.995 - ETA: 1s - loss: 0.0344 - acc: 0.995 - ETA: 1s - loss: 0.0343 - acc: 0.995 - ETA: 1s - loss: 0.0339 - acc: 0.995 - ETA: 1s - loss: 0.0345 - acc: 0.995 - ETA: 1s - loss: 0.0349 - acc: 0.995 - ETA: 1s - loss: 0.0353 - acc: 0.994 - ETA: 1s - loss: 0.0349 - acc: 0.995 - ETA: 1s - loss: 0.0358 - acc: 0.994 - ETA: 0s - loss: 0.0359 - acc: 0.994 - ETA: 0s - loss: 0.0357 - acc: 0.995 - ETA: 0s - loss: 0.0356 - acc: 0.994 - ETA: 0s - loss: 0.0353 - acc: 0.995 - ETA: 0s - loss: 0.0350 - acc: 0.995 - ETA: 0s - loss: 0.0346 - acc: 0.995 - ETA: 0s - loss: 0.0343 - acc: 0.995 - ETA: 0s - loss: 0.0343 - acc: 0.995 - ETA: 0s - loss: 0.0342 - acc: 0.995 - ETA: 0s - loss: 0.0342 - acc: 0.995 - ETA: 0s - loss: 0.0345 - acc: 0.995 - ETA: 0s - loss: 0.0343 - acc: 0.995 - ETA: 0s - loss: 0.0344 - acc: 0.995 - ETA: 0s - loss: 0.0342 - acc: 0.996 - ETA: 0s - loss: 0.0345 - acc: 0.995 - ETA: 0s - loss: 0.0344 - acc: 0.995 - ETA: 0s - loss: 0.0347 - acc: 0.995 - 3s 446us/step - loss: 0.0343 - acc: 0.9958 - val_loss: 0.6576 - val_acc: 0.8132\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.57936\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - ETA: 4s - loss: 0.0171 - acc: 1.000 - ETA: 3s - loss: 0.0186 - acc: 1.000 - ETA: 3s - loss: 0.0262 - acc: 0.996 - ETA: 3s - loss: 0.0258 - acc: 0.997 - ETA: 3s - loss: 0.0246 - acc: 0.997 - ETA: 3s - loss: 0.0270 - acc: 0.995 - ETA: 2s - loss: 0.0255 - acc: 0.995 - ETA: 2s - loss: 0.0294 - acc: 0.995 - ETA: 2s - loss: 0.0284 - acc: 0.996 - ETA: 2s - loss: 0.0295 - acc: 0.995 - ETA: 2s - loss: 0.0293 - acc: 0.995 - ETA: 2s - loss: 0.0279 - acc: 0.996 - ETA: 2s - loss: 0.0310 - acc: 0.995 - ETA: 2s - loss: 0.0304 - acc: 0.996 - ETA: 2s - loss: 0.0297 - acc: 0.996 - ETA: 2s - loss: 0.0300 - acc: 0.995 - ETA: 2s - loss: 0.0300 - acc: 0.995 - ETA: 2s - loss: 0.0306 - acc: 0.995 - ETA: 2s - loss: 0.0307 - acc: 0.995 - ETA: 2s - loss: 0.0298 - acc: 0.996 - ETA: 2s - loss: 0.0299 - acc: 0.996 - ETA: 2s - loss: 0.0312 - acc: 0.996 - ETA: 1s - loss: 0.0308 - acc: 0.996 - ETA: 1s - loss: 0.0300 - acc: 0.996 - ETA: 1s - loss: 0.0292 - acc: 0.996 - ETA: 1s - loss: 0.0293 - acc: 0.996 - ETA: 1s - loss: 0.0289 - acc: 0.996 - ETA: 1s - loss: 0.0288 - acc: 0.996 - ETA: 1s - loss: 0.0291 - acc: 0.996 - ETA: 1s - loss: 0.0287 - acc: 0.996 - ETA: 1s - loss: 0.0285 - acc: 0.996 - ETA: 1s - loss: 0.0289 - acc: 0.996 - ETA: 1s - loss: 0.0286 - acc: 0.996 - ETA: 1s - loss: 0.0288 - acc: 0.996 - ETA: 1s - loss: 0.0289 - acc: 0.996 - ETA: 1s - loss: 0.0288 - acc: 0.996 - ETA: 1s - loss: 0.0285 - acc: 0.996 - ETA: 1s - loss: 0.0292 - acc: 0.996 - ETA: 1s - loss: 0.0292 - acc: 0.996 - ETA: 0s - loss: 0.0289 - acc: 0.996 - ETA: 0s - loss: 0.0294 - acc: 0.996 - ETA: 0s - loss: 0.0292 - acc: 0.996 - ETA: 0s - loss: 0.0298 - acc: 0.995 - ETA: 0s - loss: 0.0297 - acc: 0.996 - ETA: 0s - loss: 0.0294 - acc: 0.996 - ETA: 0s - loss: 0.0295 - acc: 0.995 - ETA: 0s - loss: 0.0303 - acc: 0.995 - ETA: 0s - loss: 0.0307 - acc: 0.995 - ETA: 0s - loss: 0.0308 - acc: 0.995 - ETA: 0s - loss: 0.0308 - acc: 0.995 - ETA: 0s - loss: 0.0309 - acc: 0.995 - ETA: 0s - loss: 0.0309 - acc: 0.995 - ETA: 0s - loss: 0.0314 - acc: 0.995 - ETA: 0s - loss: 0.0316 - acc: 0.995 - 3s 466us/step - loss: 0.0316 - acc: 0.9951 - val_loss: 0.6671 - val_acc: 0.8144\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.57936\n",
      "Epoch 16/20\n",
      "6680/6680 [==============================] - ETA: 2s - loss: 0.0223 - acc: 1.000 - ETA: 2s - loss: 0.0314 - acc: 0.993 - ETA: 2s - loss: 0.0326 - acc: 0.993 - ETA: 2s - loss: 0.0322 - acc: 0.993 - ETA: 2s - loss: 0.0288 - acc: 0.994 - ETA: 2s - loss: 0.0274 - acc: 0.995 - ETA: 2s - loss: 0.0275 - acc: 0.996 - ETA: 2s - loss: 0.0271 - acc: 0.996 - ETA: 2s - loss: 0.0256 - acc: 0.997 - ETA: 2s - loss: 0.0249 - acc: 0.997 - ETA: 2s - loss: 0.0242 - acc: 0.997 - ETA: 2s - loss: 0.0262 - acc: 0.997 - ETA: 2s - loss: 0.0263 - acc: 0.997 - ETA: 2s - loss: 0.0287 - acc: 0.997 - ETA: 1s - loss: 0.0279 - acc: 0.997 - ETA: 1s - loss: 0.0275 - acc: 0.997 - ETA: 1s - loss: 0.0271 - acc: 0.997 - ETA: 1s - loss: 0.0275 - acc: 0.997 - ETA: 1s - loss: 0.0276 - acc: 0.997 - ETA: 1s - loss: 0.0275 - acc: 0.996 - ETA: 1s - loss: 0.0271 - acc: 0.997 - ETA: 1s - loss: 0.0271 - acc: 0.996 - ETA: 1s - loss: 0.0270 - acc: 0.996 - ETA: 1s - loss: 0.0269 - acc: 0.997 - ETA: 1s - loss: 0.0267 - acc: 0.997 - ETA: 1s - loss: 0.0266 - acc: 0.996 - ETA: 1s - loss: 0.0264 - acc: 0.997 - ETA: 1s - loss: 0.0273 - acc: 0.996 - ETA: 1s - loss: 0.0279 - acc: 0.996 - ETA: 1s - loss: 0.0279 - acc: 0.996 - ETA: 1s - loss: 0.0284 - acc: 0.996 - ETA: 1s - loss: 0.0282 - acc: 0.996 - ETA: 1s - loss: 0.0282 - acc: 0.996 - ETA: 1s - loss: 0.0282 - acc: 0.996 - ETA: 0s - loss: 0.0278 - acc: 0.996 - ETA: 0s - loss: 0.0276 - acc: 0.996 - ETA: 0s - loss: 0.0277 - acc: 0.996 - ETA: 0s - loss: 0.0281 - acc: 0.996 - ETA: 0s - loss: 0.0298 - acc: 0.996 - ETA: 0s - loss: 0.0298 - acc: 0.996 - ETA: 0s - loss: 0.0298 - acc: 0.996 - ETA: 0s - loss: 0.0296 - acc: 0.996 - ETA: 0s - loss: 0.0294 - acc: 0.996 - ETA: 0s - loss: 0.0294 - acc: 0.996 - ETA: 0s - loss: 0.0292 - acc: 0.996 - ETA: 0s - loss: 0.0291 - acc: 0.996 - ETA: 0s - loss: 0.0289 - acc: 0.996 - ETA: 0s - loss: 0.0288 - acc: 0.996 - ETA: 0s - loss: 0.0294 - acc: 0.996 - ETA: 0s - loss: 0.0293 - acc: 0.996 - ETA: 0s - loss: 0.0291 - acc: 0.996 - ETA: 0s - loss: 0.0291 - acc: 0.996 - 3s 443us/step - loss: 0.0291 - acc: 0.9966 - val_loss: 0.6648 - val_acc: 0.8240\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.57936\n",
      "Epoch 17/20\n",
      "6680/6680 [==============================] - ETA: 3s - loss: 0.0164 - acc: 1.000 - ETA: 2s - loss: 0.0352 - acc: 0.987 - ETA: 2s - loss: 0.0367 - acc: 0.986 - ETA: 2s - loss: 0.0329 - acc: 0.988 - ETA: 2s - loss: 0.0292 - acc: 0.991 - ETA: 2s - loss: 0.0278 - acc: 0.991 - ETA: 2s - loss: 0.0289 - acc: 0.991 - ETA: 2s - loss: 0.0269 - acc: 0.992 - ETA: 2s - loss: 0.0264 - acc: 0.992 - ETA: 2s - loss: 0.0247 - acc: 0.993 - ETA: 1s - loss: 0.0242 - acc: 0.994 - ETA: 1s - loss: 0.0236 - acc: 0.994 - ETA: 1s - loss: 0.0233 - acc: 0.994 - ETA: 1s - loss: 0.0231 - acc: 0.995 - ETA: 1s - loss: 0.0228 - acc: 0.995 - ETA: 1s - loss: 0.0227 - acc: 0.995 - ETA: 1s - loss: 0.0222 - acc: 0.996 - ETA: 1s - loss: 0.0218 - acc: 0.996 - ETA: 1s - loss: 0.0217 - acc: 0.996 - ETA: 1s - loss: 0.0224 - acc: 0.996 - ETA: 1s - loss: 0.0222 - acc: 0.996 - ETA: 1s - loss: 0.0220 - acc: 0.996 - ETA: 1s - loss: 0.0219 - acc: 0.996 - ETA: 1s - loss: 0.0216 - acc: 0.996 - ETA: 1s - loss: 0.0219 - acc: 0.996 - ETA: 1s - loss: 0.0228 - acc: 0.996 - ETA: 1s - loss: 0.0225 - acc: 0.996 - ETA: 1s - loss: 0.0235 - acc: 0.996 - ETA: 1s - loss: 0.0235 - acc: 0.996 - ETA: 0s - loss: 0.0235 - acc: 0.996 - ETA: 0s - loss: 0.0238 - acc: 0.996 - ETA: 0s - loss: 0.0242 - acc: 0.996 - ETA: 0s - loss: 0.0240 - acc: 0.996 - ETA: 0s - loss: 0.0239 - acc: 0.996 - ETA: 0s - loss: 0.0237 - acc: 0.996 - ETA: 0s - loss: 0.0236 - acc: 0.996 - ETA: 0s - loss: 0.0242 - acc: 0.996 - ETA: 0s - loss: 0.0244 - acc: 0.996 - ETA: 0s - loss: 0.0255 - acc: 0.995 - ETA: 0s - loss: 0.0253 - acc: 0.996 - ETA: 0s - loss: 0.0259 - acc: 0.995 - ETA: 0s - loss: 0.0257 - acc: 0.996 - ETA: 0s - loss: 0.0265 - acc: 0.995 - ETA: 0s - loss: 0.0267 - acc: 0.995 - ETA: 0s - loss: 0.0270 - acc: 0.995 - 3s 392us/step - loss: 0.0268 - acc: 0.9957 - val_loss: 0.6519 - val_acc: 0.8240\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.57936\n",
      "Epoch 18/20\n",
      "6680/6680 [==============================] - ETA: 3s - loss: 0.0375 - acc: 1.000 - ETA: 2s - loss: 0.0247 - acc: 1.000 - ETA: 2s - loss: 0.0219 - acc: 1.000 - ETA: 2s - loss: 0.0179 - acc: 1.000 - ETA: 2s - loss: 0.0175 - acc: 1.000 - ETA: 2s - loss: 0.0181 - acc: 1.000 - ETA: 2s - loss: 0.0199 - acc: 0.998 - ETA: 2s - loss: 0.0190 - acc: 0.999 - ETA: 2s - loss: 0.0191 - acc: 0.998 - ETA: 2s - loss: 0.0192 - acc: 0.998 - ETA: 2s - loss: 0.0218 - acc: 0.997 - ETA: 2s - loss: 0.0253 - acc: 0.996 - ETA: 1s - loss: 0.0242 - acc: 0.996 - ETA: 1s - loss: 0.0263 - acc: 0.996 - ETA: 1s - loss: 0.0260 - acc: 0.996 - ETA: 1s - loss: 0.0254 - acc: 0.996 - ETA: 1s - loss: 0.0248 - acc: 0.996 - ETA: 1s - loss: 0.0250 - acc: 0.996 - ETA: 1s - loss: 0.0249 - acc: 0.996 - ETA: 1s - loss: 0.0243 - acc: 0.996 - ETA: 1s - loss: 0.0241 - acc: 0.997 - ETA: 1s - loss: 0.0236 - acc: 0.997 - ETA: 1s - loss: 0.0232 - acc: 0.997 - ETA: 1s - loss: 0.0236 - acc: 0.997 - ETA: 1s - loss: 0.0237 - acc: 0.997 - ETA: 1s - loss: 0.0237 - acc: 0.997 - ETA: 1s - loss: 0.0234 - acc: 0.997 - ETA: 1s - loss: 0.0233 - acc: 0.997 - ETA: 1s - loss: 0.0229 - acc: 0.997 - ETA: 1s - loss: 0.0227 - acc: 0.997 - ETA: 1s - loss: 0.0226 - acc: 0.997 - ETA: 1s - loss: 0.0225 - acc: 0.997 - ETA: 1s - loss: 0.0222 - acc: 0.997 - ETA: 0s - loss: 0.0220 - acc: 0.997 - ETA: 0s - loss: 0.0222 - acc: 0.997 - ETA: 0s - loss: 0.0224 - acc: 0.997 - ETA: 0s - loss: 0.0224 - acc: 0.997 - ETA: 0s - loss: 0.0226 - acc: 0.997 - ETA: 0s - loss: 0.0228 - acc: 0.997 - ETA: 0s - loss: 0.0240 - acc: 0.996 - ETA: 0s - loss: 0.0242 - acc: 0.996 - ETA: 0s - loss: 0.0240 - acc: 0.996 - ETA: 0s - loss: 0.0244 - acc: 0.996 - ETA: 0s - loss: 0.0250 - acc: 0.996 - ETA: 0s - loss: 0.0248 - acc: 0.996 - ETA: 0s - loss: 0.0251 - acc: 0.996 - ETA: 0s - loss: 0.0250 - acc: 0.996 - ETA: 0s - loss: 0.0248 - acc: 0.996 - ETA: 0s - loss: 0.0248 - acc: 0.996 - ETA: 0s - loss: 0.0248 - acc: 0.995 - 3s 430us/step - loss: 0.0248 - acc: 0.9960 - val_loss: 0.6516 - val_acc: 0.8228\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.57936\n",
      "Epoch 19/20\n",
      "6680/6680 [==============================] - ETA: 3s - loss: 0.0138 - acc: 1.000 - ETA: 2s - loss: 0.0148 - acc: 0.993 - ETA: 2s - loss: 0.0305 - acc: 0.993 - ETA: 2s - loss: 0.0261 - acc: 0.992 - ETA: 2s - loss: 0.0237 - acc: 0.993 - ETA: 2s - loss: 0.0255 - acc: 0.991 - ETA: 2s - loss: 0.0239 - acc: 0.992 - ETA: 2s - loss: 0.0253 - acc: 0.992 - ETA: 2s - loss: 0.0242 - acc: 0.993 - ETA: 2s - loss: 0.0232 - acc: 0.994 - ETA: 2s - loss: 0.0263 - acc: 0.993 - ETA: 2s - loss: 0.0262 - acc: 0.993 - ETA: 1s - loss: 0.0267 - acc: 0.993 - ETA: 1s - loss: 0.0263 - acc: 0.994 - ETA: 1s - loss: 0.0263 - acc: 0.994 - ETA: 1s - loss: 0.0258 - acc: 0.994 - ETA: 1s - loss: 0.0275 - acc: 0.993 - ETA: 1s - loss: 0.0267 - acc: 0.994 - ETA: 1s - loss: 0.0270 - acc: 0.994 - ETA: 1s - loss: 0.0264 - acc: 0.994 - ETA: 1s - loss: 0.0264 - acc: 0.994 - ETA: 1s - loss: 0.0262 - acc: 0.994 - ETA: 1s - loss: 0.0256 - acc: 0.994 - ETA: 1s - loss: 0.0253 - acc: 0.995 - ETA: 1s - loss: 0.0248 - acc: 0.995 - ETA: 1s - loss: 0.0244 - acc: 0.995 - ETA: 1s - loss: 0.0243 - acc: 0.995 - ETA: 1s - loss: 0.0240 - acc: 0.995 - ETA: 1s - loss: 0.0236 - acc: 0.996 - ETA: 0s - loss: 0.0236 - acc: 0.995 - ETA: 0s - loss: 0.0235 - acc: 0.996 - ETA: 0s - loss: 0.0233 - acc: 0.995 - ETA: 0s - loss: 0.0239 - acc: 0.995 - ETA: 0s - loss: 0.0236 - acc: 0.996 - ETA: 0s - loss: 0.0235 - acc: 0.995 - ETA: 0s - loss: 0.0234 - acc: 0.995 - ETA: 0s - loss: 0.0235 - acc: 0.995 - ETA: 0s - loss: 0.0233 - acc: 0.995 - ETA: 0s - loss: 0.0243 - acc: 0.995 - ETA: 0s - loss: 0.0253 - acc: 0.995 - ETA: 0s - loss: 0.0251 - acc: 0.995 - ETA: 0s - loss: 0.0249 - acc: 0.995 - ETA: 0s - loss: 0.0250 - acc: 0.995 - ETA: 0s - loss: 0.0255 - acc: 0.995 - ETA: 0s - loss: 0.0257 - acc: 0.995 - ETA: 0s - loss: 0.0279 - acc: 0.994 - 3s 391us/step - loss: 0.0279 - acc: 0.9945 - val_loss: 0.6564 - val_acc: 0.8240\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.57936\n",
      "Epoch 20/20\n",
      "3776/6680 [===============>..............] - ETA: 2s - loss: 0.0508 - acc: 0.968 - ETA: 2s - loss: 0.0354 - acc: 0.987 - ETA: 2s - loss: 0.0326 - acc: 0.989 - ETA: 2s - loss: 0.0251 - acc: 0.992 - ETA: 2s - loss: 0.0227 - acc: 0.994 - ETA: 2s - loss: 0.0224 - acc: 0.995 - ETA: 2s - loss: 0.0247 - acc: 0.994 - ETA: 2s - loss: 0.0235 - acc: 0.995 - ETA: 2s - loss: 0.0254 - acc: 0.994 - ETA: 2s - loss: 0.0299 - acc: 0.993 - ETA: 2s - loss: 0.0295 - acc: 0.993 - ETA: 2s - loss: 0.0286 - acc: 0.993 - ETA: 2s - loss: 0.0278 - acc: 0.994 - ETA: 1s - loss: 0.0274 - acc: 0.994 - ETA: 1s - loss: 0.0278 - acc: 0.993 - ETA: 1s - loss: 0.0276 - acc: 0.993 - ETA: 1s - loss: 0.0269 - acc: 0.993 - ETA: 1s - loss: 0.0265 - acc: 0.993 - ETA: 1s - loss: 0.0257 - acc: 0.994 - ETA: 1s - loss: 0.0269 - acc: 0.993 - ETA: 1s - loss: 0.0266 - acc: 0.993 - ETA: 1s - loss: 0.0262 - acc: 0.994 - ETA: 1s - loss: 0.0277 - acc: 0.993 - ETA: 1s - loss: 0.0269 - acc: 0.993 - ETA: 1s - loss: 0.0267 - acc: 0.994 - ETA: 1s - loss: 0.0262 - acc: 0.994 - ETA: 1s - loss: 0.0258 - acc: 0.994 - ETA: 1s - loss: 0.0256 - acc: 0.994 - ETA: 1s - loss: 0.0249 - acc: 0.994 - ETA: 1s - loss: 0.0248 - acc: 0.994"
     ]
    }
   ],
   "source": [
    "Resnet50_model.fit(train_DogResnet50, train_targets, \n",
    "          validation_data=(valid_DogResnet50, valid_targets),\n",
    "          epochs=20, batch_size=32, callbacks=[checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the model weights with the best validation loss.\n",
    "Resnet50_model.load_weights(r'C:\\Users\\Bhumika Singh\\Desktop\\Dog breed\\saved_models\\weights.best.ResNet50.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate classification accuracy on the test dataset.\n",
    "Resnet50_predictions = [np.argmax(Resnet50_model.predict(np.expand_dims(feature, axis=0))) for feature in test_DogResnet50]\n",
    "\n",
    "# Report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(Resnet50_predictions)==np.argmax(test_targets, axis=1))/len(Resnet50_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)\n",
    "\n",
    "def extract_Resnet50(tensor): \n",
    "    return ResNet50(weights='imagenet',include_top=False,pooling='avg').predict(preprocess_input(tensor))\n",
    "### Function takes a path to an image as input and returns predicted dog breed\n",
    "def dog_breed(img_path):\n",
    "    # extract bottleneck features\n",
    "    bottleneck_feature = extract_Resnet50(path_to_tensor(img_path))\n",
    "    bottleneck_feature = np.expand_dims(bottleneck_feature, axis=0)\n",
    "    bottleneck_feature = np.expand_dims(bottleneck_feature, axis=0)\n",
    "    #bottleneck_feature = np.expand_dims(bottleneck_feature, axis=0)\n",
    "    #obtain predicted vector\n",
    "    predicted_vector = Resnet50_model.predict(bottleneck_feature)\n",
    "    # return dog breed that is predicted by the model\n",
    "    return dog_names[np.argmax(predicted_vector)]\n",
    "\n",
    "def dog_breed_predictor(img_path):\n",
    "    # determine the predicted dog breed\n",
    "    breed = dog_breed(img_path) \n",
    "    # display the image\n",
    "    img = cv2.imread(img_path)\n",
    "    cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb)\n",
    "    plt.show()\n",
    "    # display relevant predictor result\n",
    "    if dog_detector(img_path):\n",
    "        print(\"This dog's breed is: \" + str(breed).split(\"\\\\\")[-1]) \n",
    "\n",
    "    else:\n",
    "        print(\"I don't know what this is.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dog_breed_predictor(r'C:\\Users\\Bhumika Singh\\Desktop\\Dog breed\\images\\2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
